{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point,LineString\n",
    "import networkx as nx\n",
    "from shapely.ops import split, snap\n",
    "from shapely.geometry import Point, LineString\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the road dataset\n",
    "roads = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\tl_2023_06083_roads_sbco.gpkg\")\n",
    "# Dissolve the road lines to merge connected segments\n",
    "dissolved_roads = roads.dissolve(by='LINEARID') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersections & Deadends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the start and end points of each line\n",
    "start_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[0]))\n",
    "end_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[-1]))\n",
    "# Concatenate the start and end points into a single GeoSeries using pd.concat()\n",
    "all_points = gpd.GeoSeries(pd.concat([start_points, end_points]), crs=roads.crs)\n",
    "# Count the occurrence of each point\n",
    "point_counts = all_points.value_counts()\n",
    "\n",
    "\n",
    "# Filter the points that appear only once (intersections & deadends)\n",
    "intersections_deadends = point_counts[point_counts == 1]\n",
    "# Create a dictionary with the dead end points and their counts\n",
    "intersections_deadends_data = {'geometry': intersections_deadends.index, 'count': intersections_deadends.values}\n",
    " #Create a GeoDataFrame with the dead end points\n",
    "intersections_deadends_data_points = gpd.GeoDataFrame(intersections_deadends_data, crs=roads.crs)\n",
    "# Save the dead end points to a new shapefile\n",
    "intersections_deadends_data_points.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_intersection_deadends.gpkg\", driver='GPKG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deadends\n",
    "## converts a dataset of roads into a graph representation and identifies dead-end points within that network.\n",
    "\n",
    "* Graph Initialization: The process begins with the initialization of a graph. In this context, a graph is a mathematical structure used to model pairwise relations between objects. Here, roads and intersections are modeled as edges and nodes, respectively.\n",
    "* Geometry Simplification and Conversion: Each road segment (line geometry) from the dataset is simplified to remove minor irregularities and potential complexities. This simplification helps in avoiding inaccuracies when converting these geometries into a graph format. The simplified line geometries are then converted into a series of points (nodes in the graph), and consecutive points are connected by edges. This effectively builds the network where paths (edges) between points (nodes) represent segments of the road.\n",
    "* Identification of Dead Ends: Once the graph is built, the code identifies dead ends in the network. A dead end is recognized by having a node with only one connected edge (degree of 1). This means there is no alternate path from that node, signifying the end of a road without any junctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_dissolved = roads.dissolve(by='LINEARID') \n",
    "# Initialize a new graph. This will be used to store the road network where nodes represent junctions or endpoints of roads, and edges represent the roads themselves.\n",
    "G = nx.Graph()\n",
    "\n",
    "# Iterate over each row in the dissolved roads GeoDataFrame. Each row corresponds to a road segment.\n",
    "for index, row in roads_dissolved.iterrows():\n",
    "    # Simplify the geometry of the road segment to remove minor variations and potential self-intersections. This is important for accurately converting the geometries into a graph structure without unnecessary complexity.\n",
    "    line = row.geometry.simplify(tolerance=0.01)\n",
    "    \n",
    "    # Check if the simplified geometry is a LineString (a simple line shape). We only want to process line shapes as these represent the roads.\n",
    "    if isinstance(line, LineString):\n",
    "        # Convert the line's coordinates into a list of tuples. Each tuple represents a point (node) on the line.\n",
    "        points = list(map(tuple, line.coords))\n",
    "        \n",
    "        # Add these points as a path in the graph. This connects each consecutive pair of points with an edge, effectively building the road network in graph form.\n",
    "        nx.add_path(G, points)\n",
    "\n",
    "# Identify all nodes in the graph that have a degree of 1. A node with a degree of 1 only has one connection (edge) to another node, which means it is an endpoint without any further continuation - a dead end.\n",
    "dead_ends = [node for node, degree in G.degree() if degree == 1]\n",
    "\n",
    "# Convert the list of dead end nodes (points) back into a GeoDataFrame for further spatial analysis. This allows us to use geographic functions on the points.\n",
    "dead_ends_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy([p[0] for p in dead_ends], [p[1] for p in dead_ends]), crs=roads.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dead end points to a new shapefile\n",
    "dead_ends_gdf.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_deadends.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial difference\n",
    " #This operation returns the geometric difference of points in intersections_deadends that are not in dead_end_points.\n",
    "true_intersections = gpd.overlay(intersections_deadends_data_points, dead_ends_gdf, how='difference')\n",
    "\n",
    "# Now true_intersections contains only the intersection points that are not dead ends.\n",
    "# Optionally, save to file\n",
    "true_intersections.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_intersections.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QGIS\n",
    "* Using roads layer use ***Split with line*** using roads twice\n",
    "* using  '***Extract specific vertices***' with 0, -1 as input on 'Split' layer, produces 'Vertices'\n",
    "* Take difference between 'Vertices' and 'sbco_deadends' produced from this notebook, produces 'Difference'\n",
    "* Using 'Difference' again take difference using 'true_intersection' produced from this notebook, this produces another 'Differece' layer which is the remaining intersections not captured in this code.\n",
    "* edit attribute table with field calculator, existing column 'fid', @row_number\n",
    "Result is dependent on quality of original road layer. REQUIRES manual inspection, especially in long isolated roads and in urban areas with many intersections. In long roads a random vertix can be sometimes found that ties one road together. In urban areas with high number of intersections the many vertices are harder to capture. \n",
    "\n",
    "If 100% coverage of intersections is desired, — this analysis doesn't absolutely require it as the roads that are missing intersections reach an intersection or deadend — then the reccomendation is that after manual inspection and removal of unwanted points, merge the three layers of sbco_deadends, sbco_intersections, and the final difference layer. In qgis use the extract all vertices tool and take the difference with the merged layer. This will produce an extreme amount of points, create a blank shapefile, cut and paste the intersection points desired manually.\n",
    "\n",
    "Using simplify on roads  may help reduce when extracting all vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vertices = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_missing_vertices.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN coordinates in each geometry\n",
    "valid_points = missing_vertices[~missing_vertices.geometry.apply(lambda geom: np.isnan(geom.x) or np.isnan(geom.y))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points['type'] = 'intersection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points = valid_points[['type', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_points.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\valid_vertices.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_deadends.gpkg\"\n",
    "sbco_deadends = gpd.read_file(filepath)\n",
    "\n",
    "\n",
    "filepath = r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_intersections.gpkg\"\n",
    "sbco_intersections = gpd.read_file(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbco_deadends['type'] = 'deadend'\n",
    "sbco_deadends = sbco_deadends[['type', 'geometry']]\n",
    "sbco_deadends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbco_intersections['type'] = 'intersection'\n",
    "sbco_intersections = sbco_intersections[['type', 'geometry']]\n",
    "sbco_intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadends_intersections = gpd.GeoDataFrame(pd.concat([sbco_deadends, sbco_intersections, valid_points], ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadends_intersections.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\clean_deadends_intersections.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwmp = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\RWMP_AREA_2229.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwmp_deadends_intersections = gpd.clip(deadends_intersections, rwmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwmp_deadends_intersections.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\rwmp_deadends_intersections.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Egress Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmwp_road = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\rwmp_road_split.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\tl_2023_06083_roads_sbco_split.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points to get intersections and deadends\n",
    "intersections = deadends_intersections[deadends_intersections['type'] == 'intersection']\n",
    "deadends = deadends_intersections[deadends_intersections['type'] == 'deadend']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold single egress roads\n",
    "single_egress_roads = []\n",
    "\n",
    "# Loop through each road in the dataset\n",
    "for index, road in roads.iterrows():\n",
    "    # Check if the road intersects with dead end points\n",
    "    intersects_deadends = deadends.intersects(road.geometry)\n",
    "    if sum(intersects_deadends) == 1:  # Only one dead end\n",
    "        single_egress_roads.append(road)\n",
    "\n",
    "# Convert list to GeoDataFrame\n",
    "single_egress_roads = gpd.GeoDataFrame(single_egress_roads, columns=roads.columns, crs=roads.crs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_egress_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_egress_roads.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\single_egress_roads_sbco.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Identify intersection points for single egress roads\n",
    "def find_intersections(egress_roads, all_intersections):\n",
    "    # Properly initialize an empty GeoDataFrame with a geometry column\n",
    "    egress_points = gpd.GeoDataFrame(columns=['geometry'], crs=egress_roads.crs)\n",
    "    \n",
    "    for road in egress_roads.geometry:\n",
    "        # Buffer the road slightly to ensure all potential intersections are captured\n",
    "        road_buffer = road.buffer(5)  # Adjust the buffer size as needed based on your spatial unit\n",
    "        # Find intersections that are within the road buffer\n",
    "        intersecting_points = all_intersections[all_intersections.intersects(road_buffer)]\n",
    "        # Concatenate current egress_points with new intersecting_points\n",
    "        egress_points = pd.concat([egress_points, intersecting_points], ignore_index=True)\n",
    "\n",
    "    # Ensure the result is a GeoDataFrame with the correct CRS\n",
    "    egress_points = gpd.GeoDataFrame(egress_points, geometry='geometry', crs=egress_roads.crs)\n",
    "    \n",
    "    return egress_points.drop_duplicates(subset='geometry')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egress_points = find_intersections(single_egress_roads, intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egress_points = egress_points[['type', 'geometry']]\n",
    "egress_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egress_points.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\egress_points_sbco.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert intersection points to a MultiPoint object (necessary for the split operation)\n",
    "intersection_points = intersections.geometry.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_roads(road, points):\n",
    "    if points.intersects(road.geometry):\n",
    "        return split(road.geometry, points)\n",
    "    else:\n",
    "        return [road.geometry]\n",
    "\n",
    "# Apply the split function to each road segment\n",
    "split_roads_layer = rmwp_road.copy()\n",
    "split_roads_layer['geometry'] = split_roads_layer.apply(lambda x: split_roads(x, intersection_points), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since split can create multiple geometries, you need to 'explode' them into separate rows\n",
    "split_roads_layer = split_roads_layer.explode().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_roads_layer = gpd.GeoDataFrame(split_roads_layer, crs=rmwp_road.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_roads_layer.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\split_roads_layer.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify nodes that, when removed, increase the number of connected components - these nodes represent single egress points.\n",
    "# cut_points = list(nx.articulation_points(G))\n",
    "\n",
    "# # Convert these nodes back to a GeoDataFrame for spatial analysis\n",
    "# cut_points_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy([p[0] for p in cut_points], [p[1] for p in cut_points]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming roads_dissolved is your GeoDataFrame of roads\n",
    "# G = nx.Graph()\n",
    "\n",
    "# # Convert line geometries to graph, focusing only on true endpoints\n",
    "# for line in roads_dissolved.geometry:\n",
    "#     if isinstance(line, LineString):\n",
    "#         # Simplify the line to minimize unnecessary intermediate points\n",
    "#         simplified_line = line.simplify(tolerance=0.01)\n",
    "#         endpoints = [simplified_line.coords[0], simplified_line.coords[-1]]\n",
    "#         nx.add_path(G, endpoints)\n",
    "\n",
    "# # Use DBSCAN or similar to cluster endpoints to mitigate multiple close points issue\n",
    "# coords = [point for point, degree in G.nodes(data=True) if G.degree(point) == 1]\n",
    "# db = DBSCAN(eps=10, min_samples=1).fit(coords)  # Adjust eps based on your spatial resolution needs\n",
    "# clusters = db.labels_\n",
    "\n",
    "# # Convert clustered endpoints back to a GeoDataFrame\n",
    "# clustered_points = [MultiPoint([coords[i] for i in range(len(coords)) if clusters[i] == k]).centroid for k in set(clusters)]\n",
    "# dead_ends_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy([p.x for p in clustered_points], [p.y for p in clustered_points]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying articulation points and analyzing their impact\n",
    "articulation_points = list(nx.articulation_points(G))\n",
    "impact_dict = {}\n",
    "\n",
    "# Analyzing the size of components when an articulation point is removed\n",
    "for point in articulation_points:\n",
    "    G_temp = G.copy()\n",
    "    G_temp.remove_node(point)\n",
    "    components = list(nx.connected_components(G_temp))\n",
    "    # Find the largest component size when the point is removed\n",
    "    largest_component_size = max([len(comp) for comp in components])\n",
    "    total_size = len(G_temp.nodes())\n",
    "    isolated_size = total_size - largest_component_size\n",
    "    # Store the impact information\n",
    "    impact_dict[point] = isolated_size\n",
    "\n",
    "# Filtering to find significant single egress points\n",
    "significant_points = {k: v for k, v in impact_dict.items() if v > 50}  # adjust 50 to your specific threshold\n",
    "\n",
    "# Convert significant articulation points back to GeoDataFrame\n",
    "significant_points_gdf = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy([p[0] for p in significant_points.keys()], [p[1] for p in significant_points.keys()]),\n",
    "    crs=roads.crs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dead end points to a new shapefile\n",
    "significant_points_gdf.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_single_egress_points2.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the start and end points of each line\n",
    "# start_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[0]))\n",
    "# end_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[-1]))\n",
    "# # Concatenate the start and end points into a single GeoSeries using pd.concat()\n",
    "# all_points = gpd.GeoSeries(pd.concat([start_points, end_points]), crs=roads.crs)\n",
    "# # Count the occurrence of each point\n",
    "# point_counts = all_points.value_counts()\n",
    "\n",
    "\n",
    "# # Filter the points that appear only once (dead ends)\n",
    "# dead_ends = point_counts[point_counts == 1]\n",
    "# # Create a dictionary with the dead end points and their counts\n",
    "# dead_end_data = {'geometry': dead_ends.index, 'count': dead_ends.values}\n",
    "#  #Create a GeoDataFrame with the dead end points\n",
    "# dead_end_points = gpd.GeoDataFrame(dead_end_data, crs=roads.crs)\n",
    "# # Save the dead end points to a new shapefile\n",
    "# dead_end_points.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_deadends.gpkg\", driver='GPKG')\n",
    "# #2\n",
    "\n",
    "# # Create a spatial index for the road lines\n",
    "# spatial_index = dissolved_roads.sindex\n",
    "\n",
    "# # Function to check if a point is a dead end\n",
    "# def is_dead_end(point):\n",
    "#     # Create a small buffer around the point\n",
    "#     buffer_dist = 1e-5  # Adjust the buffer distance as needed\n",
    "#     buffer = point.buffer(buffer_dist)\n",
    "    \n",
    "#     # Find the indices of the lines that intersect the buffer\n",
    "#     possible_matches_index = list(spatial_index.intersection(buffer.bounds))\n",
    "#     possible_matches = dissolved_roads.iloc[possible_matches_index]\n",
    "    \n",
    "#     # Check if the point touches exactly one line geometry\n",
    "#     touching_lines = [line for line in possible_matches.geometry if point.touches(line)]\n",
    "    \n",
    "#     return len(touching_lines) == 1\n",
    "# # Function to check if a point is a dead end\n",
    "# def is_dead_end(point):\n",
    "#     # Create a small buffer around the point\n",
    "#     buffer_dist = 1e-8  # Adjust the buffer distance as needed\n",
    "#     buffer = point.buffer(buffer_dist)\n",
    "    \n",
    "#     # Find the indices of the lines that intersect the buffer\n",
    "#     possible_matches_index = list(spatial_index.intersection(buffer.bounds))\n",
    "#     possible_matches = dissolved_roads.iloc[possible_matches_index]\n",
    "    \n",
    "#     # Check if the point touches any line geometries\n",
    "#     touches_line = any(point.touches(line) for line in possible_matches.geometry)\n",
    "    \n",
    "#     return not touches_line\n",
    " \n",
    "\n",
    "# # Identify the dead end points\n",
    "# dead_ends2 = all_points[all_points.apply(is_dead_end)]\n",
    "# # Create a GeoDataFrame with the dead end points\n",
    "# dead_end_points2 = gpd.GeoDataFrame(geometry=dead_ends2, crs=roads.crs)\n",
    "\n",
    "\n",
    "# # Read the road dataset\n",
    "# roads = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\tl_2023_06083_roads_sbco.gpkg\")\n",
    "# # Dissolve the road lines to merge connected segments\n",
    "# dissolved_roads = roads.dissolve(by='LINEARID') \n",
    "# # Reset the index of dissolved_roads\n",
    "# dissolved_roads = dissolved_roads.reset_index()\n",
    "# # Extract the start and end points of each line\n",
    "# start_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[0]))\n",
    "# end_points = dissolved_roads.geometry.apply(lambda x: Point(x.coords[-1]))\n",
    "# # Concatenate the start and end points into a single GeoSeries\n",
    "# all_points = pd.concat([start_points, end_points])\n",
    "\n",
    "# # Create a DataFrame where LINEARID is repeated for each start and end point\n",
    "# repeated_linearid = dissolved_roads.loc[dissolved_roads.index.repeat(2), 'LINEARID'].reset_index(drop=True)\n",
    "# # Create a GeoDataFrame with all points and their corresponding LINEARID\n",
    "# all_points_gdf = gpd.GeoDataFrame({'geometry': all_points, 'LINEARID': repeated_linearid})\n",
    "\n",
    "# # Count the number of occurrences of each LINEARID for each point\n",
    "# linearid_counts = all_points_gdf.groupby(all_points_gdf.geometry)['LINEARID'].count()\n",
    "\n",
    "# # Identify the dead end points (points with only one occurrence of LINEARID)\n",
    "# dead_ends = linearid_counts[linearid_counts == 1].index\n",
    "\n",
    "# # Create a GeoDataFrame with the dead end points\n",
    "# dead_end_points = gpd.GeoDataFrame(geometry=dead_ends, crs=roads.crs)\n",
    "\n",
    "# # Save the dead end points to a new shapefile\n",
    "# dead_end_points.to_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\sbco_deadends.gpkg\", driver='GPKG')\n",
    "# # Load the road data\n",
    "# roads = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\tl_2023_06083_roads_sbco.gpkg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road  Order System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the layers as GeoDataFrames\n",
    "road_order_data = r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\road_order\\road_order.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = gpd.read_file(r\"C:\\Users\\bsf31\\Documents\\post-meds\\data\\signal\\road_order\\base\\clean_deadends_intersections.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_ends =  gpd.read_file(road_order_data, layer = 'sbco_deadends')\n",
    "egress_points = gpd.read_file(road_order_data, layer='egress_points_sbco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dead = clean.overlay(dead_ends, how = 'symmetric_difference')\n",
    "remove_egress = remove_dead.overlay(egress_points, how = 'symmetric_difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_egress.rename(columns = {'egress_order_1': 'egress_order'}, inplace = True)\n",
    "remove_egress.drop(columns = ['egress_order_2', 'type_2'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_egress.to_file(road_order_data,layer = 'intersections_wo_egresspoints', driver = 'GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "intersections = gpd.read_file(road_order_data, layer= 'intersections_wo_egresspoints')\n",
    "roads = gpd.read_file(road_order_data, layer = 'all_wo_single_egress_roads')\n",
    "single_egress_roads = gpd.read_file(road_order_data, layer = 'single_egress_roads_sbco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egress_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_egress_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assign_egress_order(intersection_layer, road_layer, egress_point_layer, single_egress_road_layer):\n",
    "\n",
    "    # Create a dictionary to store the egress_order values for each feature ID\n",
    "    egress_order_dict = {}\n",
    "\n",
    "    # Create a NetworkX graph from the road layer\n",
    "    G = nx.Graph()\n",
    "    for _, road in roads.iterrows():\n",
    "        if road.geometry.type == 'MultiLineString':\n",
    "            for line in road.geometry.geoms:\n",
    "                start_node = line.coords[0]\n",
    "                end_node = line.coords[-1]\n",
    "                G.add_edge(start_node, end_node, geometry=line, fid=tuple(road.index))\n",
    "        else:\n",
    "            start_node = road.geometry.coords[0]\n",
    "            end_node = road.geometry.coords[-1]\n",
    "            G.add_edge(start_node, end_node, geometry=road.geometry, fid=tuple(road.index))\n",
    "\n",
    "    # Assign egress_order values to intersection layer\n",
    "    for _, intersection in intersections.iterrows():\n",
    "        intersection_id = tuple(intersection.index)\n",
    "        intersection_geom = intersection.geometry\n",
    "\n",
    "        # Find the connected road segments\n",
    "        connected_roads = []\n",
    "        for _, road in roads.iterrows():\n",
    "            if road.geometry.intersects(intersection_geom):\n",
    "                connected_roads.append(road)\n",
    "\n",
    "        # Find the highest egress_order value among the connected roads\n",
    "        max_egress_order = 0\n",
    "        for road in connected_roads:\n",
    "            road_id = tuple(road.index)\n",
    "            if road_id in egress_order_dict:\n",
    "                max_egress_order = max(max_egress_order, egress_order_dict[road_id])\n",
    "\n",
    "        # Assign the highest egress_order value to the intersection\n",
    "        egress_order_dict[intersection_id] = max_egress_order\n",
    "\n",
    "    # Assign egress_order values to road layer\n",
    "    for _, road in roads.iterrows():\n",
    "        road_id = tuple(road.index)\n",
    "        road_geom = road.geometry\n",
    "\n",
    "        # Check if the road is connected to an egress point\n",
    "        for _, egress_point in egress_points.iterrows():\n",
    "            if road_geom.intersects(egress_point.geometry):\n",
    "                egress_order_dict[road_id] = 3\n",
    "                break\n",
    "\n",
    "        # Check if the road is a single egress road\n",
    "        for _, single_egress_road in single_egress_roads.iterrows():\n",
    "            if road_geom.equals(single_egress_road.geometry):\n",
    "                egress_order_dict[road_id] = 2\n",
    "                break\n",
    "\n",
    "        # Check if the road is connected to an intersection\n",
    "        if road_id not in egress_order_dict:\n",
    "            for _, intersection in intersections.iterrows():\n",
    "                if road_geom.intersects(intersection.geometry):\n",
    "                    intersection_id = tuple(intersection.index)\n",
    "                    if intersection_id in egress_order_dict:\n",
    "                        egress_order_dict[road_id] = egress_order_dict[intersection_id]\n",
    "                        break\n",
    "\n",
    "    # Update the egress_order values in the intersection layer\n",
    "    intersections['egress_order'] = intersections.index.map(lambda x: egress_order_dict.get(tuple(x), None))\n",
    "\n",
    "    # Update the egress_order values in the road layer\n",
    "    roads['egress_order'] = roads.index.map(lambda x: egress_order_dict.get(tuple(x), None))\n",
    "\n",
    "    return intersections, roads\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to assign egress_order values\n",
    "updated_intersections, updated_roads = assign_egress_order(intersections, roads, egress_points, single_egress_roads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated layers to new shapefiles\n",
    "updated_intersections.to_file('path/to/updated_intersection_layer.shp')\n",
    "updated_roads.to_file('path/to/updated_road_layer.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(road):\n",
    "    road_data = road[1]  # Access the row data\n",
    "    if road_data.geometry.type == 'MultiLineString':\n",
    "        lines = [(line.coords[0], line.coords[-1], {'geometry': line, 'fid': road_data.name}) for line in road_data.geometry.geoms]\n",
    "    else:\n",
    "        lines = [(road_data.geometry.coords[0], road_data.geometry.coords[-1], {'geometry': road_data.geometry, 'fid': road_data.name})]\n",
    "    return lines\n",
    "\n",
    "def assign_egress_order(intersections, roads, egress_points, single_egress_roads):\n",
    "    # Create a dictionary to store the egress_order values for each feature ID\n",
    "    egress_order_dict = {}\n",
    "\n",
    "    # Create a NetworkX graph from the road layer\n",
    "    with Pool() as pool:\n",
    "        edges = pool.map(create_graph, roads.iterrows())\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from([edge for sublist in edges for edge in sublist])\n",
    "\n",
    "    # Assign egress_order values to intersection layer\n",
    "    def assign_intersection_order(intersection):\n",
    "        intersection_id = intersection.name\n",
    "        intersection_geom = intersection.geometry\n",
    "\n",
    "        # Find the connected road segments\n",
    "        connected_roads = roads[roads.geometry.intersects(intersection_geom)]\n",
    "\n",
    "        # Find the highest egress_order value among the connected roads\n",
    "        max_egress_order = connected_roads.apply(lambda x: egress_order_dict.get(x.name, 0)).max()\n",
    "\n",
    "        # Assign the highest egress_order value to the intersection\n",
    "        egress_order_dict[intersection_id] = max_egress_order\n",
    "\n",
    "    intersections.apply(assign_intersection_order, axis=1)\n",
    "\n",
    "    # Assign egress_order values to road layer\n",
    "    def assign_road_order(road):\n",
    "        road_id = road.name\n",
    "        road_geom = road.geometry\n",
    "\n",
    "        # Check if the road is connected to an egress point\n",
    "        if road_geom.intersects(egress_points.unary_union):\n",
    "            egress_order_dict[road_id] = 3\n",
    "            return\n",
    "\n",
    "        # Check if the road is a single egress road\n",
    "        if road_geom.equals(single_egress_roads.unary_union):\n",
    "            egress_order_dict[road_id] = 2\n",
    "            return\n",
    "\n",
    "        # Check if the road is connected to an intersection\n",
    "        if road_id not in egress_order_dict:\n",
    "            connected_intersections = intersections[intersections.geometry.intersects(road_geom)]\n",
    "            if not connected_intersections.empty:\n",
    "                intersection_id = connected_intersections.iloc[0].name\n",
    "                if intersection_id in egress_order_dict:\n",
    "                    egress_order_dict[road_id] = egress_order_dict[intersection_id]\n",
    "\n",
    "    roads.apply(assign_road_order, axis=1)\n",
    "\n",
    "    # Update the egress_order values in the intersection layer\n",
    "    intersections['egress_order'] = intersections.index.map(egress_order_dict)\n",
    "\n",
    "    # Update the egress_order values in the road layer\n",
    "    roads['egress_order'] = roads.index.map(egress_order_dict)\n",
    "\n",
    "    return intersections, roads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_intersections, updated_roads = assign_egress_order(intersections, roads, egress_points, single_egress_roads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
